{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# === Imports & Config ===\nimport os\nimport json\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\nRANDOM_SEED = 42\nN_FOLDS = 5\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T16:45:25.609227Z","iopub.execute_input":"2025-11-19T16:45:25.609833Z","iopub.status.idle":"2025-11-19T16:45:25.615055Z","shell.execute_reply.started":"2025-11-19T16:45:25.609804Z","shell.execute_reply":"2025-11-19T16:45:25.614377Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"\n# === Paths (Kaggle) ===\nTRAIN_PATH = \"/kaggle/input/playground-series-s5e11/train.csv\"\nTEST_PATH  = \"/kaggle/input/playground-series-s5e11/test.csv\"\nSAMPLE_SUB_PATH = \"/kaggle/input/playground-series-s5e11/sample_submission.csv\"\nSUBMIT_NAME = \"submission.csv\"\n\nTARGET_COL = \"loan_paid_back\"  # competition target name\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T19:20:12.785663Z","iopub.execute_input":"2025-11-19T19:20:12.785944Z","iopub.status.idle":"2025-11-19T19:20:12.790255Z","shell.execute_reply.started":"2025-11-19T19:20:12.785923Z","shell.execute_reply":"2025-11-19T19:20:12.789560Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# === Utilities ===\ndef set_seed(seed: int = RANDOM_SEED):\n    np.random.seed(seed)\n\n\ndef read_data(train_path: str, test_path: str, sample_sub_path: str):\n    train = pd.read_csv(train_path)\n    test = pd.read_csv(test_path)\n    sample_sub = pd.read_csv(sample_sub_path)\n    print(f\"Train shape: {train.shape} | Test shape: {test.shape}\")\n    return train, test, sample_sub\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T19:20:16.990877Z","iopub.execute_input":"2025-11-19T19:20:16.991182Z","iopub.status.idle":"2025-11-19T19:20:16.996419Z","shell.execute_reply.started":"2025-11-19T19:20:16.991161Z","shell.execute_reply":"2025-11-19T19:20:16.995657Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"def split_target_and_id(train: pd.DataFrame, test: pd.DataFrame, target_col: str):\n    # Capture test ids early and drop from frames\n    if \"id\" in test.columns:\n        test_ids = test[\"id\"].copy()\n        test = test.drop(columns=[\"id\"])\n    else:\n        test_ids = pd.Series(np.arange(len(test)), name=\"id\")\n\n    # Drop id from train if present\n    if \"id\" in train.columns:\n        train = train.drop(columns=[\"id\"])\n\n    # Extract target and features\n    if target_col not in train.columns:\n        raise ValueError(f\"Target column '{target_col}' not found in train.\")\n    y = train[target_col].astype(int).copy()\n    X = train.drop(columns=[target_col]).copy()\n\n    return X, y, test, test_ids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T16:45:25.698327Z","iopub.execute_input":"2025-11-19T16:45:25.698866Z","iopub.status.idle":"2025-11-19T16:45:25.722929Z","shell.execute_reply.started":"2025-11-19T16:45:25.698845Z","shell.execute_reply":"2025-11-19T16:45:25.722149Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def basic_impute_and_encode(X: pd.DataFrame, test: pd.DataFrame):\n    \"\"\"\n    Combined-factorization approach for stable category mapping.\n    Optionally, we’ll also return cat feature names for CatBoost.\n    \"\"\"\n    num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n    cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n\n    combined = pd.concat(\n        [X.assign(_is_train=1), test.assign(_is_train=0)],\n        ignore_index=True\n    )\n\n    # Numeric: median impute\n    for c in num_cols:\n        combined[c] = combined[c].fillna(combined[c].median())\n\n    # Categorical: stringify + factorize for consistent mapping\n    for c in cat_cols:\n        combined[c] = combined[c].astype(str).fillna(\"NA\")\n        codes, _ = pd.factorize(combined[c], sort=True)\n        combined[c] = codes\n\n    X_proc = combined[combined[\"_is_train\"] == 1].drop(columns=[\"_is_train\"]).reset_index(drop=True)\n    T_proc = combined[combined[\"_is_train\"] == 0].drop(columns=[\"_is_train\"]).reset_index(drop=True)\n\n    return X_proc, T_proc, num_cols, cat_cols","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T16:45:25.724054Z","iopub.execute_input":"2025-11-19T16:45:25.724639Z","iopub.status.idle":"2025-11-19T16:45:25.740910Z","shell.execute_reply.started":"2025-11-19T16:45:25.724612Z","shell.execute_reply":"2025-11-19T16:45:25.740285Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Feature engineering with safe column checks.\"\"\"\n    df = df.copy()\n\n    loan_col   = \"loan_amount\" if \"loan_amount\" in df.columns else None\n    income_col = \"annual_income\" if \"annual_income\" in df.columns else None\n    emp_col    = \"employment_length\" if \"employment_length\" in df.columns else None\n    cred_col   = \"credit_score\" if \"credit_score\" in df.columns else None\n    rate_col   = \"interest_rate\" if \"interest_rate\" in df.columns else None\n    ratio_col  = \"debt_to_income_ratio\" if \"debt_to_income_ratio\" in df.columns else None\n\n    # Derived ratios\n    if loan_col and income_col:\n        df[\"loan_income_ratio\"] = df[loan_col] / (df[income_col] + 1.0)\n    if emp_col and cred_col:\n        df[\"emp_credit_ratio\"] = df[emp_col] / (df[cred_col] + 1.0)\n    if rate_col and ratio_col:\n        df[\"loan_rate_ratio\"] = df[rate_col] * df[ratio_col]\n\n    # Binning examples (robust to duplicates)\n    if income_col:\n        try:\n            df[\"income_bin\"] = pd.qcut(df[income_col], 10, labels=False, duplicates=\"drop\")\n        except Exception:\n            pass\n\n    if \"age\" in df.columns:\n        df[\"age_bin\"] = pd.cut(df[\"age\"], bins=[18, 25, 35, 45, 60, 100], labels=False)\n    elif \"person_age\" in df.columns:\n        df[\"age_bin\"] = pd.cut(df[\"person_age\"], bins=[18, 25, 35, 45, 60, 100], labels=False)\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T16:45:25.742012Z","iopub.execute_input":"2025-11-19T16:45:25.742773Z","iopub.status.idle":"2025-11-19T16:45:25.762181Z","shell.execute_reply.started":"2025-11-19T16:45:25.742726Z","shell.execute_reply":"2025-11-19T16:45:25.761458Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def train_models_with_cv(X: pd.DataFrame, y: pd.Series, X_test: pd.DataFrame, n_folds: int = N_FOLDS, seed: int = RANDOM_SEED):\n    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n\n    oof_xgb = np.zeros(len(X))\n    oof_lgb = np.zeros(len(X))\n    oof_cat = np.zeros(len(X))\n\n    pred_xgb = np.zeros(len(X_test))\n    pred_lgb = np.zeros(len(X_test))\n    pred_cat = np.zeros(len(X_test))\n\n    # Optional: CatBoost native categorical indices (after encoding they’re numeric, so keep empty)\n    cat_idx = []  # if you keep factorization, CatBoost sees them as numeric; leave empty or rework to native strings.\n\n    # Class imbalance helper\n    pos = y.sum()\n    neg = len(y) - pos\n    scale_pos_weight = (neg / max(pos, 1.0))\n\n    for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n        print(f\"\\n=== Fold {fold}/{n_folds} ===\")\n        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n\n        # Align columns with test\n        common = X_tr.columns.intersection(X_test.columns)\n        X_tr, X_va, X_te = X_tr[common], X_va[common], X_test[common]\n\n        # XGBoost\n        xgb = XGBClassifier(\n            n_estimators=3000,\n            learning_rate=0.02,\n            max_depth=5,\n            subsample=0.8,\n            colsample_bytree=0.8,\n            reg_lambda=1.2,\n            random_state=seed,\n            eval_metric=\"auc\",\n            tree_method=\"hist\",\n            scale_pos_weight=scale_pos_weight\n        )\n        xgb.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], early_stopping_rounds=200, verbose=False)\n        oof_xgb[va_idx] = xgb.predict_proba(X_va)[:, 1]\n        pred_xgb += xgb.predict_proba(X_te)[:, 1] / n_folds\n\n        # LightGBM\n        lgb = LGBMClassifier(\n            n_estimators=3000,\n            learning_rate=0.02,\n            max_depth=-1,\n            subsample=0.8,\n            colsample_bytree=0.8,\n            num_leaves=63,\n            reg_lambda=1.2,\n            random_state=seed,\n            class_weight=None  # or \"balanced\"\n        )\n        lgb.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], eval_metric=\"auc\", callbacks=[])\n        oof_lgb[va_idx] = lgb.predict_proba(X_va)[:, 1]\n        pred_lgb += lgb.predict_proba(X_te)[:, 1] / n_folds\n\n        # CatBoost\n        cat = CatBoostClassifier(\n            iterations=2000,\n            learning_rate=0.03,\n            depth=6,\n            l2_leaf_reg=3.0,\n            subsample=0.8,\n            eval_metric=\"AUC\",\n            random_seed=seed,\n            verbose=False\n        )\n        # If you decide to keep native categoricals, feed cat_features=cat_idx and use un-factorized data.\n        cat.fit(X_tr, y_tr, eval_set=(X_va, y_va), use_best_model=True)\n        oof_cat[va_idx] = cat.predict_proba(X_va)[:, 1]\n        pred_cat += cat.predict_proba(X_te)[:, 1] / n_folds\n\n        # Per-fold diagnostics\n        print(\n    f\"AUC XGB={roc_auc_score(y_va, oof_xgb[va_idx]):.5f} | \"\n    f\"LGB={roc_auc_score(y_va, oof_lgb[va_idx]):.5f} | \"\n    f\"CAT={roc_auc_score(y_va, oof_cat[va_idx]):.5f}\" )\n    \n    print(\"\\nOOF AUCs:\")\n    print(\"XGBoost :\", roc_auc_score(y, oof_xgb))\n    print(\"LightGBM:\", roc_auc_score(y, oof_lgb))\n    print(\"CatBoost:\", roc_auc_score(y, oof_cat))\n\n    return (oof_xgb, oof_lgb, oof_cat), (pred_xgb, pred_lgb, pred_cat)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T16:45:25.823897Z","iopub.execute_input":"2025-11-19T16:45:25.824491Z","iopub.status.idle":"2025-11-19T16:45:25.838098Z","shell.execute_reply.started":"2025-11-19T16:45:25.824466Z","shell.execute_reply":"2025-11-19T16:45:25.837267Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def optimize_blend(oof_list, y_true, grid_step: int = 21):\n    \"\"\"\n    Simple grid search on weights (w1, w2, w3) s.t. w1 + w2 + w3 = 1\n    \"\"\"\n    def oof_auc(weights):\n        w1, w2, w3 = weights\n        blend = w1 * oof_list[0] + w2 * oof_list[1] + w3 * oof_list[2]\n        return roc_auc_score(y_true, blend)\n\n    best = {\"w\": (1/3, 1/3, 1/3), \"auc\": -1.0}\n    grid = np.linspace(0.0, 1.0, grid_step)\n\n    for w1 in grid:\n        for w2 in grid:\n            w3 = 1.0 - w1 - w2\n            if w3 < 0 or w3 > 1:\n                continue\n            auc = oof_auc((w1, w2, w3))\n            if auc > best[\"auc\"]:\n                best = {\"w\": (w1, w2, w3), \"auc\": auc}\n\n    print(f\"\\nBest Blend AUC: {best['auc']:.6f} with weights {best['w']}\")\n    return best[\"w\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T16:45:25.839563Z","iopub.execute_input":"2025-11-19T16:45:25.839839Z","iopub.status.idle":"2025-11-19T16:45:25.860664Z","shell.execute_reply.started":"2025-11-19T16:45:25.839819Z","shell.execute_reply":"2025-11-19T16:45:25.859985Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def make_submission(test_ids: pd.Series, test_preds: np.ndarray, out_path: str = SUBMIT_NAME):\n    sub = pd.DataFrame({\n        \"id\": test_ids.astype(int),\n        \"loan_paid_back\": np.clip(test_preds.astype(float), 0.0, 1.0)\n    })\n    sub.to_csv(out_path, index=False)\n    print(f\"Saved: {out_path}\")\n    return sub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T16:45:25.861274Z","iopub.execute_input":"2025-11-19T16:45:25.861494Z","iopub.status.idle":"2025-11-19T16:45:25.883857Z","shell.execute_reply.started":"2025-11-19T16:45:25.861478Z","shell.execute_reply":"2025-11-19T16:45:25.882945Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"\n# === Main flow ===\ndef main():\n    set_seed(RANDOM_SEED)\n\n    train, test, sample_sub = read_data(TRAIN_PATH, TEST_PATH, SAMPLE_SUB_PATH)\n\n    # Split target and ids\n    X, y, X_test, test_ids = split_target_and_id(train, test, TARGET_COL)\n\n    # Preprocess (median-impute numeric + factorize categoricals)\n    Xp, Tp, num_cols, cat_cols = basic_impute_and_encode(X, X_test)\n\n    # Optional feature engineering\n    Xp = engineer_features(Xp)\n    Tp = engineer_features(Tp)\n\n    # Ensure aligned columns\n    common = Xp.columns.intersection(Tp.columns)\n    Xp, Tp = Xp[common], Tp[common]\n\n    # Train + OOF/Test predictions\n    oof_list, test_list = train_models_with_cv(Xp, y, Tp, n_folds=N_FOLDS, seed=RANDOM_SEED)\n\n    # Blend optimization\n    w1, w2, w3 = optimize_blend(oof_list, y, grid_step=21)\n    test_blend = w1 * test_list[0] + w2 * test_list[1] + w3 * test_list[2]\n\n    # Submission\n    sub = make_submission(test_ids, test_blend, SUBMIT_NAME)\n    display(sub.head())\n\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T17:22:48.937224Z","iopub.execute_input":"2025-11-19T17:22:48.937870Z","iopub.status.idle":"2025-11-19T18:02:39.525892Z","shell.execute_reply.started":"2025-11-19T17:22:48.937843Z","shell.execute_reply":"2025-11-19T18:02:39.524908Z"}},"outputs":[{"name":"stdout","text":"Train shape: (593994, 13) | Test shape: (254569, 12)\n\n=== Fold 1/5 ===\n[LightGBM] [Info] Number of positive: 379595, number of negative: 95600\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011244 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1849\n[LightGBM] [Info] Number of data points in the train set: 475195, number of used features: 14\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.798819 -> initscore=1.378932\n[LightGBM] [Info] Start training from score 1.378932\nAUC XGB=0.92286 | LGB=0.92291 | CAT=0.92276\n\n=== Fold 2/5 ===\n[LightGBM] [Info] Number of positive: 379595, number of negative: 95600\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011233 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1849\n[LightGBM] [Info] Number of data points in the train set: 475195, number of used features: 14\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.798819 -> initscore=1.378932\n[LightGBM] [Info] Start training from score 1.378932\nAUC XGB=0.92245 | LGB=0.92253 | CAT=0.92235\n\n=== Fold 3/5 ===\n[LightGBM] [Info] Number of positive: 379595, number of negative: 95600\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011124 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1849\n[LightGBM] [Info] Number of data points in the train set: 475195, number of used features: 14\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.798819 -> initscore=1.378932\n[LightGBM] [Info] Start training from score 1.378932\nAUC XGB=0.92043 | LGB=0.92109 | CAT=0.92071\n\n=== Fold 4/5 ===\n[LightGBM] [Info] Number of positive: 379595, number of negative: 95600\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011335 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1848\n[LightGBM] [Info] Number of data points in the train set: 475195, number of used features: 14\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.798819 -> initscore=1.378932\n[LightGBM] [Info] Start training from score 1.378932\nAUC XGB=0.92131 | LGB=0.92219 | CAT=0.92171\n\n=== Fold 5/5 ===\n[LightGBM] [Info] Number of positive: 379596, number of negative: 95600\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011125 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1849\n[LightGBM] [Info] Number of data points in the train set: 475196, number of used features: 14\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.798820 -> initscore=1.378935\n[LightGBM] [Info] Start training from score 1.378935\nAUC XGB=0.92099 | LGB=0.92152 | CAT=0.92134\n\nOOF AUCs:\nXGBoost : 0.9216052063688791\nLightGBM: 0.9220434538034994\nCatBoost: 0.9217731504794546\n\nBest Blend AUC: 0.922625 with weights (0.15000000000000002, 0.45, 0.39999999999999997)\nSaved: submission.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"       id  loan_paid_back\n0  593994        0.911399\n1  593995        0.973542\n2  593996        0.432107\n3  593997        0.896232\n4  593998        0.951887","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>loan_paid_back</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>593994</td>\n      <td>0.911399</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>593995</td>\n      <td>0.973542</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>593996</td>\n      <td>0.432107</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>593997</td>\n      <td>0.896232</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>593998</td>\n      <td>0.951887</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16}]}